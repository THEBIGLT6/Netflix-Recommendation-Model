{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"Dataset/users.csv\")\n",
    "movies = pd.read_csv(\"Dataset/movies.csv\")\n",
    "watch_history = pd.read_csv(\"Dataset/watch_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Data in Users ---\n",
      "                Missing Count  Missing %\n",
      "age                      1229  11.932039\n",
      "gender                    824   8.000000\n",
      "monthly_spend            1017   9.873786\n",
      "household_size           1545  15.000000\n",
      "\n",
      "--- Missing Data in Movies ---\n",
      "                    Missing Count  Missing %\n",
      "genre_secondary               667  64.134615\n",
      "imdb_rating                   150  14.423077\n",
      "production_budget             675  64.903846\n",
      "box_office_revenue            709  68.173077\n",
      "number_of_seasons             751  72.211538\n",
      "number_of_episodes            719  69.134615\n",
      "\n",
      "--- Missing Data in Watch History ---\n",
      "                        Missing Count  Missing %\n",
      "watch_duration_minutes          12332  11.744762\n",
      "progress_percentage              8514   8.108571\n",
      "user_rating                     83903  79.907619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Missing Data Summary ---\n",
    "# Define function to summarize missing values and print missing data for each dataset.\n",
    "\n",
    "def missing_summary(df, feat):\n",
    "    missing_count = df.isna().sum()\n",
    "    missing_percent = (missing_count/len(df))*100\n",
    "    summary = pd.DataFrame({'Missing Count': missing_count, 'Missing %': missing_percent})\n",
    "    summary = summary[summary[\"Missing Count\"] > 0]\n",
    "    print(f\"--- Missing Data in {feat} ---\")\n",
    "    print(f\"{summary}\\n\")\n",
    "    return summary\n",
    "\n",
    "miss_users = missing_summary(users, \"Users\")\n",
    "miss_movies = missing_summary(movies, \"Movies\")\n",
    "miss_watch = missing_summary(watch_history, \"Watch History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Cleaning/Preprocessing ---\n",
    "# Drop irrelevant columns and fill missing numeric/categorical values for users, movies and watch_history.\n",
    "\n",
    "movies = movies.drop_duplicates(subset=['movie_id', 'title']).reset_index(drop=True)\n",
    "movies = movies.drop(columns=['production_budget', 'box_office_revenue','number_of_seasons', 'number_of_episodes'])\n",
    "movies['imdb_rating'] = movies['imdb_rating'].fillna(movies['imdb_rating'].mean())\n",
    "\n",
    "users['age'] = users['age'].fillna(users['age'].median())\n",
    "users['gender'] = users['gender'].fillna('Unknown')\n",
    "\n",
    "watch_history = watch_history.drop(columns=['user_rating'], errors='ignore')\n",
    "watch_history['watch_duration_minutes'] = watch_history['watch_duration_minutes'].fillna(watch_history['watch_duration_minutes'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User Genre Profiles ---\n",
    "# Aggregate watch history by user and genre to create normalized user genre preferences and join with user averages.\n",
    "\n",
    "user_profiles = (\n",
    "    watch_history.groupby('user_id')\n",
    "    .agg({'watch_duration_minutes': 'mean',\n",
    "          'progress_percentage': 'mean'})\n",
    "    .rename(columns={'watch_duration_minutes': 'avg_watch_duration',\n",
    "                     'progress_percentage': 'avg_progress'})\n",
    ")\n",
    "\n",
    "user_genres = (\n",
    "    watch_history.merge(movies[['movie_id', 'genre_primary']], on='movie_id', how='left')\n",
    "    .groupby(['user_id', 'genre_primary']).size().unstack(fill_value=0)\n",
    ")\n",
    "user_genres = user_genres.div(user_genres.sum(axis=1), axis=0)\n",
    "user_profiles = user_profiles.join(user_genres, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Movie Feature Processing ---\n",
    "# Select movie features, standardize release year, one-hot encode primary genres, and prepare movie feature matrix.\n",
    "\n",
    "movie_features = movies[['movie_id', 'imdb_rating', 'release_year', 'genre_primary']].copy()\n",
    "movie_features['year'] = (movie_features['release_year'] - movie_features['release_year'].mean()) / movie_features['release_year'].std()\n",
    "\n",
    "genre_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "genre_encoded = genre_encoder.fit_transform(movie_features[['genre_primary']])\n",
    "genre_df = pd.DataFrame(genre_encoded, columns=genre_encoder.get_feature_names_out(['genre_primary']))\n",
    "\n",
    "movie_features = pd.concat([movie_features.drop(columns=['genre_primary']).reset_index(drop=True), genre_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge Data for Modeling ---\n",
    "# Combine watch history with user profiles and movie features; drop rows with missing target values.\n",
    "\n",
    "data = (\n",
    "    watch_history\n",
    "    .merge(user_profiles, on='user_id', how='left')\n",
    "    .merge(movie_features, on='movie_id', how='left')\n",
    ")\n",
    "data = data.dropna(subset=['watch_duration_minutes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Preparation ---\n",
    "# Select numeric features, fill missing values, scale features, and add bias column.\n",
    "\n",
    "X_user = data[user_profiles.columns].reset_index(drop=True)\n",
    "X_movie = data[movie_features.drop(columns=['movie_id']).columns].reset_index(drop=True)\n",
    "\n",
    "interaction_terms = X_user.values[:, :, None] * X_movie.values[:, None, :]\n",
    "interaction_terms = interaction_terms.reshape(X_user.shape[0], -1)\n",
    "interaction_cols = [f\"{u}*{m}\" for u in X_user.columns for m in X_movie.columns]\n",
    "\n",
    "X_all = np.hstack([X_user.values, X_movie.values, interaction_terms])\n",
    "X_all_cols = list(X_user.columns) + list(X_movie.columns) + interaction_cols\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "X = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])\n",
    "\n",
    "y = data['watch_duration_minutes'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target and Train/Test Split ---\n",
    "# Extract watch duration as target and split data into training and testing sets.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gradient Descent Function ---\n",
    "# Implement basic gradient descent to train linear regression model on scaled features.\n",
    "\n",
    "def gradient_descent(X, y, lr=0.01, epochs=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    theta = np.zeros((n_features, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_pred = X @ theta\n",
    "        error = y_pred - y\n",
    "        gradient = (2/n_samples) * X.T @ error\n",
    "        theta -= lr * gradient\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            loss = np.mean(error ** 2)\n",
    "            print(f\"Epoch {epoch}, MSE: {loss:.3f}\")\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE: 8289.704\n",
      "Epoch 100, MSE: 3794.285\n",
      "Epoch 200, MSE: 3720.077\n",
      "Epoch 300, MSE: 3717.338\n",
      "Epoch 400, MSE: 3716.308\n",
      "Epoch 500, MSE: 3715.568\n",
      "Epoch 600, MSE: 3715.015\n",
      "Epoch 700, MSE: 3714.593\n",
      "Epoch 800, MSE: 3714.269\n",
      "Epoch 900, MSE: 3714.016\n",
      "Final RMSE: 60.366\n",
      "Final R²: 0.092\n"
     ]
    }
   ],
   "source": [
    "# --- Train Model ---\n",
    "# Run gradient descent on training data to learn feature weights for predicting watch duration.\n",
    "\n",
    "theta = gradient_descent(X_train, y_train, lr=0.01, epochs=1000)\n",
    "\n",
    "y_pred = X_test @ theta\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final RMSE: {rmse:.3f}\")\n",
    "print(f\"Final R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre_primary</th>\n",
       "      <th>release_year</th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Mystery Day</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2024</td>\n",
       "      <td>9.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Big Day</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2024</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Love Day</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2022</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Dragon Dragon</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.281425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Phoenix Storm</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2023</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Dream Dream</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2022</td>\n",
       "      <td>5.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Big House</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>Love Journey</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2015</td>\n",
       "      <td>7.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>The Love</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2018</td>\n",
       "      <td>6.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Secret Mission</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2016</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title genre_primary  release_year  imdb_rating\n",
       "327     Mystery Day        Horror          2024     9.300000\n",
       "994         Big Day        Horror          2024     7.900000\n",
       "985        Love Day        Horror          2022     8.500000\n",
       "284   Dragon Dragon        Horror          2024     6.281425\n",
       "986   Phoenix Storm        Horror          2023     6.800000\n",
       "720     Dream Dream        Horror          2022     5.900000\n",
       "950       Big House        Horror          2020     6.700000\n",
       "782    Love Journey        Horror          2015     7.900000\n",
       "991        The Love        Horror          2018     6.200000\n",
       "600  Secret Mission        Horror          2016     6.500000"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Recommendation Function ---\n",
    "# Predict top N movies for a user using the trained gradient descent model and user/movie features.\n",
    "\n",
    "def recommend(user_id, n=5):\n",
    "    if user_id not in user_profiles.index:\n",
    "        print(f\"User {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    user_row = user_profiles.loc[[user_id]].reset_index(drop=True)\n",
    "    movie_matrix = movie_features.drop(columns=['movie_id']).reset_index(drop=True)\n",
    "\n",
    "    X_user_vals = user_row.values.repeat(len(movie_matrix), axis=0)\n",
    "    X_movie_vals = movie_matrix.values\n",
    "\n",
    "    interaction_vals = X_user_vals[:, :, None] * X_movie_vals[:, None, :]\n",
    "    interaction_vals = interaction_vals.reshape(len(movie_matrix), -1)\n",
    "\n",
    "    X_input_all = np.hstack([X_user_vals, X_movie_vals, interaction_vals])\n",
    "    X_input_scaled = scaler.transform(X_input_all)\n",
    "    X_input = np.hstack([np.ones((X_input_scaled.shape[0], 1)), X_input_scaled])\n",
    "\n",
    "    pred_duration = X_input @ theta\n",
    "\n",
    "    watched_movies = watch_history[watch_history['user_id'] == user_id]['movie_id'].values\n",
    "    top_indices = np.argsort(pred_duration.flatten())[::-1]\n",
    "    top_indices = [i for i in top_indices if movie_features['movie_id'].iloc[i] not in watched_movies][:n]\n",
    "\n",
    "    return movies.iloc[top_indices][['title', 'genre_primary', 'release_year', 'imdb_rating']]\n",
    "\n",
    "recommend('user_00001', 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
