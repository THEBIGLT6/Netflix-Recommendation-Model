{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"Dataset/users.csv\")\n",
    "movies = pd.read_csv(\"Dataset/movies.csv\")\n",
    "watch_history = pd.read_csv(\"Dataset/watch_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Data in Users ---\n",
      "                Missing Count  Missing %\n",
      "age                      1229  11.932039\n",
      "gender                    824   8.000000\n",
      "monthly_spend            1017   9.873786\n",
      "household_size           1545  15.000000\n",
      "\n",
      "--- Missing Data in Movies ---\n",
      "                    Missing Count  Missing %\n",
      "genre_secondary               667  64.134615\n",
      "imdb_rating                   150  14.423077\n",
      "production_budget             675  64.903846\n",
      "box_office_revenue            709  68.173077\n",
      "number_of_seasons             751  72.211538\n",
      "number_of_episodes            719  69.134615\n",
      "\n",
      "--- Missing Data in Watch History ---\n",
      "                        Missing Count  Missing %\n",
      "watch_duration_minutes          12332  11.744762\n",
      "progress_percentage              8514   8.108571\n",
      "user_rating                     83903  79.907619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Missing Data Summary ---\n",
    "# Define function to summarize missing values and print missing data for each dataset.\n",
    "\n",
    "def missing_summary(df, feat):\n",
    "    missing_count = df.isna().sum()\n",
    "    missing_percent = (missing_count/len(df))*100\n",
    "    summary = pd.DataFrame({'Missing Count': missing_count, 'Missing %': missing_percent})\n",
    "    summary = summary[summary[\"Missing Count\"] > 0]\n",
    "    print(f\"--- Missing Data in {feat} ---\")\n",
    "    print(f\"{summary}\\n\")\n",
    "    return summary\n",
    "\n",
    "miss_users = missing_summary(users, \"Users\")\n",
    "miss_movies = missing_summary(movies, \"Movies\")\n",
    "miss_watch = missing_summary(watch_history, \"Watch History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Cleaning/Preprocessing ---\n",
    "# Drop irrelevant columns and fill missing numeric/categorical values for users, movies and watch_history.\n",
    "\n",
    "movies = movies.drop_duplicates(subset=['movie_id', 'title']).reset_index(drop=True)\n",
    "movies = movies.drop(columns=['production_budget', 'box_office_revenue','number_of_seasons', 'number_of_episodes'])\n",
    "movies['imdb_rating'] = movies['imdb_rating'].fillna(movies['imdb_rating'].mean())\n",
    "\n",
    "users['age'] = users['age'].fillna(users['age'].median())\n",
    "users['gender'] = users['gender'].fillna('Unknown')\n",
    "\n",
    "watch_history = watch_history.drop(columns=['user_rating'], errors='ignore')\n",
    "watch_history['watch_duration_minutes'] = watch_history['watch_duration_minutes'].fillna(watch_history['watch_duration_minutes'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User Genre Profiles ---\n",
    "# Aggregate watch history by user and genre to create normalized user genre preferences and join with user averages.\n",
    "\n",
    "user_profiles = (\n",
    "    watch_history.groupby('user_id')\n",
    "    .agg({'watch_duration_minutes': 'mean',\n",
    "          'progress_percentage': 'mean'})\n",
    "    .rename(columns={'watch_duration_minutes': 'avg_watch_duration',\n",
    "                     'progress_percentage': 'avg_progress'})\n",
    ")\n",
    "\n",
    "user_genres = (\n",
    "    watch_history.merge(movies[['movie_id', 'genre_primary']], on='movie_id', how='left')\n",
    "    .groupby(['user_id', 'genre_primary']).size().unstack(fill_value=0)\n",
    ")\n",
    "user_genres = user_genres.div(user_genres.sum(axis=1), axis=0)\n",
    "user_profiles = user_profiles.join(user_genres, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Movie Feature Processing ---\n",
    "# Select movie features, standardize release year, one-hot encode primary genres, and prepare movie feature matrix.\n",
    "\n",
    "movie_features = movies[['movie_id', 'imdb_rating', 'release_year', 'genre_primary']].copy()\n",
    "movie_features['year'] = (movie_features['release_year'] - movie_features['release_year'].mean()) / movie_features['release_year'].std()\n",
    "\n",
    "genre_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "genre_encoded = genre_encoder.fit_transform(movie_features[['genre_primary']])\n",
    "genre_df = pd.DataFrame(genre_encoded, columns=genre_encoder.get_feature_names_out(['genre_primary']))\n",
    "\n",
    "movie_features = pd.concat([movie_features.drop(columns=['genre_primary']).reset_index(drop=True), genre_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge Data for Modeling ---\n",
    "# Combine watch history with user profiles and movie features; drop rows with missing target values.\n",
    "\n",
    "data = (\n",
    "    watch_history\n",
    "    .merge(user_profiles, on='user_id', how='left')\n",
    "    .merge(movie_features, on='movie_id', how='left')\n",
    ")\n",
    "data = data.dropna(subset=['watch_duration_minutes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Feature Preparation ---\n",
    "# Separate user and movie feature matrices, create interaction terms between them for specific user traits,\n",
    "# features are combines, standardized and prepared for model traning\n",
    "\n",
    "X_user = data[user_profiles.columns].reset_index(drop=True)\n",
    "X_movie = data[movie_features.drop(columns=['movie_id']).columns].reset_index(drop=True)\n",
    "\n",
    "interaction_terms = X_user.values[:, :, None] * X_movie.values[:, None, :]\n",
    "interaction_terms = interaction_terms.reshape(X_user.shape[0], -1)\n",
    "interaction_cols = [f\"{u}*{m}\" for u in X_user.columns for m in X_movie.columns]\n",
    "\n",
    "X_all = np.hstack([X_user.values, X_movie.values, interaction_terms])\n",
    "X_all_cols = list(X_user.columns) + list(X_movie.columns) + interaction_cols\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_all)\n",
    "X = np.hstack([np.ones((X_scaled.shape[0], 1)), X_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Target and Train/Test Split ---\n",
    "# Extract watch duration as target and split data into training and testing sets.\n",
    "\n",
    "y = data['watch_duration_minutes'].values.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Gradient Descent Function ---\n",
    "# Implement basic gradient descent to train linear regression model on scaled features.\n",
    "\n",
    "def gradient_descent(X, y, lr=0.01, epochs=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    theta = np.zeros((n_features, 1))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        y_pred = X @ theta\n",
    "        error = y_pred - y\n",
    "        gradient = (2/n_samples) * X.T @ error\n",
    "        theta -= lr * gradient\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            loss = np.mean(error ** 2)\n",
    "            print(f\"Epoch {epoch}, MSE: {loss:.3f}\")\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE: 8289.704\n",
      "Epoch 100, MSE: 3794.285\n",
      "Epoch 200, MSE: 3720.077\n",
      "Epoch 300, MSE: 3717.338\n",
      "Epoch 400, MSE: 3716.308\n",
      "Epoch 500, MSE: 3715.568\n",
      "Epoch 600, MSE: 3715.015\n",
      "Epoch 700, MSE: 3714.593\n",
      "Epoch 800, MSE: 3714.269\n",
      "Epoch 900, MSE: 3714.016\n",
      "Final RMSE: 60.366\n",
      "Final R²: 0.092\n"
     ]
    }
   ],
   "source": [
    "# --- Train Model ---\n",
    "# Run gradient descent on training data to learn feature weights for predicting watch duration.\n",
    "\n",
    "theta = gradient_descent(X_train, y_train, lr=0.01, epochs=1000)\n",
    "\n",
    "y_pred = X_test @ theta\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final RMSE: {rmse:.3f}\")\n",
    "print(f\"Final R²: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre_primary</th>\n",
       "      <th>release_year</th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Little Warrior</td>\n",
       "      <td>Action</td>\n",
       "      <td>2019</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Dream Adventure</td>\n",
       "      <td>Music</td>\n",
       "      <td>2021</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>The Dream</td>\n",
       "      <td>Action</td>\n",
       "      <td>2019</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Bright Day</td>\n",
       "      <td>Action</td>\n",
       "      <td>2018</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Love Warrior</td>\n",
       "      <td>Action</td>\n",
       "      <td>2020</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>A Quest</td>\n",
       "      <td>Action</td>\n",
       "      <td>2005</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>City Queen</td>\n",
       "      <td>History</td>\n",
       "      <td>2020</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Fire Kingdom</td>\n",
       "      <td>Action</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>Mystery Storm</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2020</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>First Hero</td>\n",
       "      <td>Action</td>\n",
       "      <td>2020</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title genre_primary  release_year  imdb_rating\n",
       "118   Little Warrior        Action          2019          8.5\n",
       "942  Dream Adventure         Music          2021          9.4\n",
       "332        The Dream        Action          2019          8.0\n",
       "164       Bright Day        Action          2018          7.6\n",
       "738     Love Warrior        Action          2020          7.1\n",
       "449          A Quest        Action          2005         10.0\n",
       "92        City Queen       History          2020          9.7\n",
       "572     Fire Kingdom        Action          2020          6.9\n",
       "408    Mystery Storm       Fantasy          2020          7.8\n",
       "41        First Hero        Action          2020          6.7"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Recommendation Function ---\n",
    "# Predict top N movies for a user using the trained gradient descent model and user/movie features.\n",
    "\n",
    "def recommend(user_id, n=5):\n",
    "    if user_id not in user_profiles.index:\n",
    "        print(f\"User {user_id} not found.\")\n",
    "        return []\n",
    "\n",
    "    user_row = user_profiles.loc[[user_id]].reset_index(drop=True)\n",
    "    movie_matrix = movie_features.drop(columns=['movie_id']).reset_index(drop=True)\n",
    "\n",
    "    X_user_vals = user_row.values.repeat(len(movie_matrix), axis=0)\n",
    "    X_movie_vals = movie_matrix.values\n",
    "\n",
    "    interaction_vals = X_user_vals[:, :, None] * X_movie_vals[:, None, :]\n",
    "    interaction_vals = interaction_vals.reshape(len(movie_matrix), -1)\n",
    "\n",
    "    X_input_all = np.hstack([X_user_vals, X_movie_vals, interaction_vals])\n",
    "    X_input_scaled = scaler.transform(X_input_all)\n",
    "    X_input = np.hstack([np.ones((X_input_scaled.shape[0], 1)), X_input_scaled])\n",
    "\n",
    "    pred_duration = X_input @ theta\n",
    "\n",
    "    watched_movies = watch_history[watch_history['user_id'] == user_id]['movie_id'].values\n",
    "    top_indices = np.argsort(pred_duration.flatten())[::-1]\n",
    "    top_indices = [i for i in top_indices if movie_features['movie_id'].iloc[i] not in watched_movies][:n]\n",
    "\n",
    "    return movies.iloc[top_indices][['title', 'genre_primary', 'release_year', 'imdb_rating']]\n",
    "\n",
    "recommend('user_02012', 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
